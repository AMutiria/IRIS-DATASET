{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5802324-e41b-4852-a67e-a7a1f4ace64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the Iris dataset into a pandas DataFrame\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "\n",
    "# (Optional) Simulate missing data for demonstration\n",
    "# df.iloc[0, 0] = None  # Uncomment to test handling missing values\n",
    "\n",
    "# Step 1: Handle missing values (if any)\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace missing values with column mean\n",
    "df[iris.feature_names] = imputer.fit_transform(df[iris.feature_names])\n",
    "\n",
    "# Step 2: Encode labels (target values)\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['target'])\n",
    "\n",
    "# Step 3: Split features and target\n",
    "X = df[iris.feature_names]\n",
    "y = df['target']\n",
    "\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 5: Train Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "rec = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Step 8: Print evaluation results\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall: {rec:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c18e6a-08f1-47b4-b315-aa1f73916704",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Setup complete! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81c16f-dbd0-4e22-bc9b-c00c3fa95836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Pixel value range: {x_train.min()} to {x_train.max()}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e2ccd-2fe5-41e2-a369-d977e98f1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(x_data, y_data, num_samples=5, title=\"Sample Images\"):\n",
    "    \"\"\"Visualize sample images from the dataset\"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(x_data[i], cmap='gray')\n",
    "        plt.title(f'Label: {y_data[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show some training examples\n",
    "visualize_samples(x_train, y_train, 5, \"Training Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6e3ee-8450-4b3d-adc7-f7bac9ed2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Normalize pixel values to 0-1 range\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for CNN (add channel dimension)\n",
    "x_train_cnn = x_train_norm.reshape(-1, 28, 28, 1)\n",
    "x_test_cnn = x_test_norm.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = 10\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"Original shape: {x_train.shape} → CNN shape: {x_train_cnn.shape}\")\n",
    "print(f\"Label shape: {y_train.shape} → Categorical shape: {y_train_cat.shape}\")\n",
    "print(\"Preprocessing complete! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77105b-641f-4d96-a25c-740d92f8fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_cnn():\n",
    "    \"\"\"Create CNN model for MNIST digit classification\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second Conv Block  \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Classification Head\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_mnist_cnn()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display architecture\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2a049-86f3-4aad-88bb-584158aca66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# Training callbacks for better results\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    x_train_cnn, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    validation_data=(x_test_cnn, y_test_cat),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training complete! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a7d8b-d323-4c0f-90f3-3258b5f65adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model...\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(x_test_cnn, verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred, average='macro')\n",
    "test_recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"\\n📊 MODEL PERFORMANCE:\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"Test Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall:    {test_recall:.4f}\")\n",
    "\n",
    "# Check if goal achieved\n",
    "if test_accuracy > 0.95:\n",
    "    print(\"🎉 SUCCESS: Achieved >95% test accuracy!\")\n",
    "else:\n",
    "    print(f\"⚠️  Current accuracy: {test_accuracy*100:.2f}%\")\n",
    "    print(\"💡 Try training longer or adjusting the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524e2f1-64a1-457e-a81e-a2d7e8d5a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Create training history plots\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax1.plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax1.set_title('Model Accuracy Over Time', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(history.history['loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax2.plot(history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax2.set_title('Model Loss Over Time', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda507f-d3b4-42b8-aadf-0184e3c8cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, x_data, y_true, num_samples=5):\n",
    "    \"\"\"Show model predictions on sample images\"\"\"\n",
    "    # Get random samples\n",
    "    indices = np.random.choice(len(x_data), num_samples, replace=False)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_data[indices], verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.suptitle('Model Predictions on Test Images', fontsize=16)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(x_data[idx].reshape(28, 28), cmap='gray')\n",
    "        \n",
    "        # Get prediction details\n",
    "        confidence = np.max(predictions[i]) * 100\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = predicted_classes[i]\n",
    "        \n",
    "        # Color code: green if correct, red if wrong\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        plt.title(f'True: {true_label} | Pred: {pred_label}\\nConfidence: {confidence:.1f}%', \n",
    "                 color=color, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show prediction statistics\n",
    "    correct = sum(y_true[indices] == predicted_classes)\n",
    "    print(f\"Predictions shown: {correct}/{num_samples} correct\")\n",
    "\n",
    "# Show predictions on test images\n",
    "print(\"🔍 Model predictions on random test images:\")\n",
    "visualize_predictions(model, x_test_cnn, y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7455f-7bb6-4c59-9e6a-d282e9d6406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
